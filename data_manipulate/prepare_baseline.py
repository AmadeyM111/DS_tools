"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ baseline –∏–∑ –ª–æ–≥–æ–≤ –¥–∏–∞–ª–æ–≥–æ–≤.
"""

import json
import re
import pandas as pd
from typing import List, Dict
from datetime import datetime


def extract_qa_pairs(jsonl_file: str) -> List[Dict]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ä—ã –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –∏–∑ JSONL –ª–æ–≥–æ–≤.
    
    Returns:
        List[Dict]: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–æ–ª—è–º–∏:
            - conversation_id: ID –¥–∏–∞–ª–æ–≥–∞
            - timestamp: –í—Ä–µ–º—è –≤–æ–ø—Ä–æ—Å–∞
            - user_query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            - bot_answer: –û—Ç–≤–µ—Ç –±–æ—Ç–∞
            - intent: –ù–∞–º–µ—Ä–µ–Ω–∏–µ (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ –ª–æ–≥–∞—Ö)
            - duration: –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    
    qa_pairs = []
    
    with open(jsonl_file, 'r', encoding='utf-8') as f:
        for line in f:
            if not line.strip():
                continue
            
            conv = json.loads(line)
            conv_id = conv.get('id', 'unknown')
            history = conv.get('history', [])
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä—ã –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
            current_question = None
            current_timestamp = None
            intent = None
            duration = None
            
            for i, msg in enumerate(history):
                msg_type = msg.get('type')
                
                # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å
                if msg_type == 'Message' and msg.get('from', {}).get('role') == 'User':
                    current_question = msg.get('text', '').strip()
                    current_timestamp = msg.get('timestamp')
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º intent –∏–∑ Event (–µ—Å–ª–∏ –µ—Å—Ç—å)
                elif msg_type == 'Event' and 'variables' in msg:
                    variables = msg.get('variables', {})
                    if 'intenet' in variables:  # –î–∞, –≤ –ª–æ–≥–∞—Ö –æ–ø–µ—á–∞—Ç–∫–∞: intenet –≤–º–µ—Å—Ç–æ intent
                        intent = variables['intenet']
                    if 'duration' in msg:
                        duration = msg['duration']
                
                # –û—Ç–≤–µ—Ç –±–æ—Ç–∞
                elif msg_type == 'Message' and msg.get('from', {}).get('role') == 'Bot':
                    bot_answer = msg.get('text', '').strip()
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                    if '–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å' in bot_answer or '–ó–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å' in bot_answer:
                        continue
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
                    if '–†–∞–¥ –±—ã–ª –ø–æ–º–æ—á—å' in bot_answer or bot_answer == '–ù–µ —É–∫–∞–∑–∞–Ω–æ':
                        continue
                    
                    # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å ‚Äî —Å–æ–∑–¥–∞—ë–º –ø–∞—Ä—É
                    if current_question:
                        qa_pairs.append({
                            'conversation_id': conv_id,
                            'timestamp': current_timestamp,
                            'user_query': current_question,
                            'bot_answer': bot_answer,
                            'intent': intent or 'unknown',
                            'duration': duration,
                        })
                        
                        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
                        current_question = None
                        intent = None
                        duration = None
    
    return qa_pairs


def categorize_answer_quality(answer: str) -> str:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞.
    
    Returns:
        'good' | 'bad' | 'clarification' | 'error'
    """
    
    answer_lower = answer.lower()
    
    # –ü–ª–æ—Ö–∏–µ –æ—Ç–≤–µ—Ç—ã (–æ—à–∏–±–∫–∏, –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏)
    bad_patterns = [
        '–Ω–µ —É–∫–∞–∑–∞–Ω–æ',
        '–Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏',
        '–Ω–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏',
        '–æ—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞',
        '–Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å',
    ]
    
    if any(pattern in answer_lower for pattern in bad_patterns):
        return 'bad'
    
    # –£—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã
    clarification_patterns = [
        '—É—Ç–æ—á–Ω–∏—Ç–µ',
        '–∫–∞–∫–∞—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —É—Å–ª—É–≥–∞',
        '–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ',
        '–∫–∞–∫–æ–π –∏–º–µ–Ω–Ω–æ',
    ]
    
    if any(pattern in answer_lower for pattern in clarification_patterns):
        return 'clarification'
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ–∑–≤–æ–Ω–∏—Ç—å (—á–∞—Å—Ç–∏—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è)
    if '—Ä–µ–∫–æ–º–µ–Ω–¥—É—é –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è' in answer_lower or '–ø–æ–∑–≤–æ–Ω–∏—Ç–µ' in answer_lower:
        return 'partial'
    
    # –•–æ—Ä–æ—à–∏–µ –æ—Ç–≤–µ—Ç—ã (—Å–æ–¥–µ—Ä–∂–∞—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é)
    if len(answer) > 100:  # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç
        return 'good'
    
    return 'neutral'


def annotate_intent_category(intent: str) -> str:
    """
    –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ—Ç intent –ø–æ —Ç–∏–ø–∞–º –∑–∞–ø—Ä–æ—Å–æ–≤.
    
    Returns:
        'price' | 'doctors' | 'location' | 'preparation' | 'other'
    """
    
    intent_lower = intent.lower()
    
    if '—Ü–µ–Ω' in intent_lower or '—Å—Ç–æ–∏–º–æ—Å—Ç' in intent_lower:
        return 'price'
    elif '–≤—Ä–∞—á' in intent_lower or '–¥–æ–∫—Ç–æ—Ä' in intent_lower:
        return 'doctors'
    elif '–∞–¥—Ä–µ—Å' in intent_lower or '—Ñ–∏–ª–∏–∞–ª' in intent_lower:
        return 'location'
    elif '–ø–æ–¥–≥–æ—Ç–æ–≤–∫' in intent_lower or '–∞–Ω–∞–ª–∏–∑' in intent_lower:
        return 'preparation'
    elif '—Å–µ–∞–Ω—Å' in intent_lower:
        return 'sessions'
    elif '–ø—Ä–æ—Ç–æ–∫–æ–ª' in intent_lower or '–æ—à–∏–±–∫' in intent_lower:
        return 'protocol_issues'
    else:
        return 'other'


def create_baseline_dataset(qa_pairs: List[Dict]) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞—ë—Ç –∏—Ç–æ–≥–æ–≤—ã–π baseline –¥–∞—Ç–∞—Å–µ—Ç.
    """
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
    df = pd.DataFrame(qa_pairs)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –æ—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞
    df['answer_quality'] = df['bot_answer'].apply(categorize_answer_quality)
    
    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∏—Ä—É–µ–º intent
    df['intent_category'] = df['intent'].apply(annotate_intent_category)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    df['query_length'] = df['user_query'].str.len()
    df['answer_length'] = df['bot_answer'].str.len()
    df['has_price_info'] = df['bot_answer'].str.contains('—Ä—É–±–ª|—Ä—É–±|‚ÇΩ|–û–ú–°|–±–µ—Å–ø–ª–∞—Ç–Ω–æ', case=False, regex=True)
    df['has_phone'] = df['bot_answer'].str.contains(r'\+7\s*\(?\d{3}\)?', regex=True)
    df['has_address'] = df['bot_answer'].str.contains('–ú–æ—Å–∫–≤–∞|–•–∏–º–∫–∏|–ö–ª—è–∑—å–º–∞|–¢–≤–µ—Ä—Å–∫–∞—è', case=False, regex=True)
    
    # –ü–∞—Ä—Å–∏–º timestamp
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    return df


def generate_test_set(df: pd.DataFrame, sample_size: int = 50) -> pd.DataFrame:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–ª—è –æ—Ü–µ–Ω–∫–∏.
    
    –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø–æ intent_category –∏ answer_quality.
    """
    
    # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ 'good' –∏ 'partial' –æ—Ç–≤–µ—Ç—ã –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ —Ç–µ—Å—Ç–∞
    test_df = df[df['answer_quality'].isin(['good', 'partial'])].copy()
    
    # –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞
    if len(test_df) > sample_size:
        test_df = test_df.groupby('intent_category', group_keys=False).apply(
            lambda x: x.sample(min(len(x), max(1, int(sample_size * len(x) / len(test_df)))))
        )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ –¥–ª—è —Ä—É—á–Ω–æ–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
    test_df['overall_quality'] = ''  # –ó–∞–ø–æ–ª–Ω–∏—Ç—å –≤—Ä—É—á–Ω—É—é: 1-5
    test_df['reference_answer'] = test_df['bot_answer']  # Ground truth
    test_df['notes'] = ''  # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
    
    return test_df.reset_index(drop=True)


# ============================================================
# MAIN
# ============================================================

if __name__ == '__main__':
    
    print("=" * 60)
    print(" –ü–û–î–ì–û–¢–û–í–ö–ê BASELINE –ò–ó –õ–û–ì–û–í –î–ò–ê–õ–û–ì–û–í")
    print("=" * 60)
    
    # 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç
    print("\n[1/5] –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç...")
    qa_pairs = extract_qa_pairs('cummulate_file.jsonl')
    print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ –ø–∞—Ä: {len(qa_pairs)}")
    
    # 2. –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
    print("\n[2/5] –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏...")
    df = create_baseline_dataset(qa_pairs)
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –î–ê–¢–ê–°–ï–¢–ê:")
    print(f"–í—Å–µ–≥–æ –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç: {len(df)}")
    print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –æ—Ç–≤–µ—Ç–æ–≤:")
    print(df['answer_quality'].value_counts())
    print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º intent:")
    print(df['intent_category'].value_counts())
    
    # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    print("\n[3/5] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    df.to_csv('baseline_full.csv', index=False, encoding='utf-8-sig')
    print("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: baseline_full.csv")
    
    # 4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞
    print("\n[4/5] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞ (50 –ø—Ä–∏–º–µ—Ä–æ–≤)...")
    test_df = generate_test_set(df, sample_size=50)
    test_df.to_csv('baseline_test_set.csv', index=False, encoding='utf-8-sig')
    print("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: baseline_test_set.csv")
    
    # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∫–æ–¥–µ
    print("\n[5/5] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON –≤–µ—Ä—Å–∏–∏...")

    available_columns = test_df.columns.tolist()
    print(f"DEBUG: –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {available_columns}")
    
    json_columns = []
    for col in ['user_query', 'bot_answer', 'intent', 'intent_category', 'answer_quality']:
        if col in available_columns:
            json_columns.append(col)

    test_json = test_df[json_columns].to_dict('records')

    for item in test_json:
        if 'bot_answer' in item:
            item['reference_answer'] = item.pop('bot_answer')

    with open('baseline_test_set.json', 'w', encoding='utf-8') as f:
        json.dump(test_json, f, ensure_ascii=False, indent=2)
    print("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: baseline_test_set.json")
    
    print("\n" + "=" * 60)
    print("‚úÖ BASELINE –ì–û–¢–û–í!")
    print("=" * 60)
    print("\n–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    print("1. –û—Ç–∫—Ä–æ–π—Ç–µ baseline_test_set.csv")
    print("2. –ó–∞–ø–æ–ª–Ω–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É 'overall_quality' (1-5)")
    print("3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–ª—è A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
